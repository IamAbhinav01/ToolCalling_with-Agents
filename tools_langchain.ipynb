{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa228b19",
   "metadata": {},
   "source": [
    "## ARXIV -->Research Paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48d2b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun,ArxivQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b243e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "arxiv = ArxivQueryRun(api_wrapper=ArxivAPIWrapper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cf3fe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Hunter × Hunter\n",
      "Summary: Hunter × Hunter (pronounced \"hunter hunter\") is a Japanese manga series written and illustrated by Yoshihiro Togashi. It has been serialized in Shueisha's shōnen manga magazine Weekly Shōnen Jump since March 1998, although the manga has frequently gone on extended hiatuses since 2006. Its chapters have been collected in 38 tankōbon volumes as of September 2024. The story focuses on a young boy named Gon Freecss who discovers that his father, who left him at a young age, is actually a world-renowned Hunter, a licensed professional who specializes in fantastical pursuits such as locating rare or unidentified animal species, treasure hunting, surveying unexplored enclaves, or hunting down lawless individuals. Gon departs on a journey to become a Hunter and eventually find his father. Along the way, Gon meets various other Hunters and encounters the paranormal.\n",
      "Hunter × Hunter was adapted into a 62-episode anime television series by Nippon Animation and directed by Kazuhiro Furuhashi, which ran on Fuji Television from October 1999 to March 2001. Three separate original video animations (OVAs) totaling 30 episodes were subsequently produced by Nippon Animation and released in Japan from 2002 to 2004. A second anime television series by Madhouse aired on Nippon Television from October 2011 to September 2014, totaling 148 episodes, with two animated theatrical films released in 2013. There are also numerous audio albums, video games, musicals, and other media based on Hunter × Hunter.\n",
      "The manga has been licensed for English release in North America by Viz Media since April 2005. Both television series have been also licensed by Viz Media, with the first series having aired on the Funimation Channel in 2009 and the second series broadcast on Adult Swim's Toonami programming block from April 2016 to June 2019.\n",
      "Hunter × Hunter has been widely acclaimed and commercially successful, becoming one of the best-selling manga series of all time with over 84 million copies in circulation worldwide by July 2022.\n",
      "\n",
      "Page: Hunter × Hunter (2011 TV series)\n",
      "Summary: Hunter × Hunter is an anime television series that aired from 2011 to 2014 based on Yoshihiro Togashi's manga series Hunter × Hunter. The story begins with a young boy named Gon Freecss, who one day discovers that the father who he thought was dead, is in fact alive and well. He learns that his father, Ging, is a legendary \"Hunter\", an individual who has proven themselves an elite member of humanity. Despite the fact that Ging left his son with his relatives in order to pursue his own dreams, Gon becomes determined to follow in his father's footsteps, pass the rigorous \"Hunter Examination\", and eventually find his father to become a Hunter in his own right.\n",
      "This second anime television series adaptation of Hunter × Hunter was announced on July 24, 2011. It is a complete reboot starting from the beginning of the original manga, with no connection to the first anime television series from 1999. Produced by Nippon TV, VAP, Shueisha and Madhouse, the series is directed by Hiroshi Kōjina, with Atsushi Maekawa and Tsutomu Kamishiro handling series composition, Takahiro Yoshimatsu designing the characters and Yoshihisa Hirano composing the music. Instead of having the old cast reprise their roles for the new adaptation, the series features an entirely new cast to voice the characters. The new series premiered airing weekly on Nippon TV and the nationwide Nippon News Network from October 2, 2011.  The series started to be collected in both DVD and Blu-ray format on January 25, 2012. Viz Media has licensed the anime for a DVD/Blu-ray release in North America with an English dub. On television, the series began airing on Adult Swim's Toonami programming block on April 17, 2016, and ended on June 23, 2019.\n",
      "The anime series' opening theme is alternated between the song \"Departure!\" and an alternate version titled \"Departure! -Second Version-\" both sung by Galneryus' voca\n",
      "--------------------------------------------------\n",
      "Published: 2019-09-08\n",
      "Title: Lecture Notes: Optimization for Machine Learning\n",
      "Authors: Elad Hazan\n",
      "Summary: Lecture notes on optimization for machine learning, derived from a course at\n",
      "Princeton University and tutorials given in MLSS, Buenos Aires, as well as\n",
      "Simons Foundation, Berkeley.\n",
      "\n",
      "Published: 2018-11-11\n",
      "Title: An Optimal Control View of Adversarial Machine Learning\n",
      "Authors: Xiaojin Zhu\n",
      "Summary: I describe an optimal control view of adversarial machine learning, where the\n",
      "dynamical system is the machine learner, the input are adversarial actions, and\n",
      "the control costs are defined by the adversary's goals to do harm and be hard\n",
      "to detect. This view encompasses many types of adversarial machine learning,\n",
      "including test-item attacks, training-data poisoning, and adversarial reward\n",
      "shaping. The view encourages adversarial machine learning researcher to utilize\n",
      "advances in control theory and reinforcement learning.\n",
      "\n",
      "Published: 2017-07-16\n",
      "Title: Minimax deviation strategies for machine learning and recognition with short learning samples\n",
      "Authors: Michail Schlesinger, Evgeniy Vodolazskiy\n",
      "Summary: The article is devoted to the problem of small learning samples in machine\n",
      "learning. The flaws of maximum likelihood learning and minimax learning are\n",
      "looked into and the concept of minimax deviation learning is introduced that is\n",
      "free of those flaws.\n"
     ]
    }
   ],
   "source": [
    "print(wikipedia.run(\"HUNTER X HUNTER\"))\n",
    "print(\"--------------------------------------------------\")\n",
    "print(arxiv.run(\"machine learning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c4ec7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wikipedia,arxiv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c62cf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b675334d-50a6-4056-bf3e-7c4b8760ba06',\n",
       " 'd432baba-9a4a-4bb5-9289-a30fc57b1f82',\n",
       " '75b36987-187a-49f1-babd-4e24fc748aa4',\n",
       " '3287f84e-a686-4cee-85b6-78730c5b4a4e',\n",
       " '1f8b2f37-56da-4124-a189-bc750f44cd71',\n",
       " 'daa3dde0-210f-4a8b-8ed5-640ffec5fbc1',\n",
       " '2d571c45-a9af-4eaa-a663-21a97077d59c',\n",
       " '8db8ad76-1381-4f07-a707-dfcedf796dd2',\n",
       " '14905194-3aa2-4a67-9369-7dfb9572e563',\n",
       " '8aad40cd-eb09-480d-9274-add34ffaa789',\n",
       " 'e66dbc04-876d-4f7d-bff5-19fef89cc502',\n",
       " 'd7f9189f-9e4f-4af7-b712-24debe4b72ec',\n",
       " '87aa9ee0-3e6e-4940-9072-244e3dbae2ef',\n",
       " '11442aa1-03e0-4ba2-a079-22ca0779f1fd',\n",
       " '8e247b16-ccd1-4a80-9a48-ef5d96bbcbe4',\n",
       " 'a1b98dfa-b701-4847-8c44-e22c59098dca',\n",
       " '3d678adc-698f-437c-aa96-b8ed724955ed',\n",
       " '0f1106d7-3680-472b-94d2-19e5ac3cb32f',\n",
       " 'ddfea6b5-e1c1-40d2-99cd-43347d97e27d',\n",
       " 'c2e86608-5ab2-4019-a05c-9c168e756081',\n",
       " '9044467f-da83-4bfd-a12f-a84effdbee8f']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import faiss\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "loader = WebBaseLoader(\"https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html\")\n",
    "docs = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "data = splitter.split_documents(docs)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "dimension = len(embeddings.embed_query(\"hello world\"))\n",
    "\n",
    "# 4. Create FAISS index\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# 5. Create FAISS vector store\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore({}),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "# 6. Add documents to the store\n",
    "vector_store.add_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e912dc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002432805A110>, search_kwargs={})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa69e38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='LangchainDocs', description='Useful for when you need to find information about Langchain', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002437C16BB50>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002432805A110>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002437C169360>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002432805A110>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(retriever=retriever,name=\"LangchainDocs\",description=\"Useful for when you need to find information about Langchain\")\n",
    "retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc14d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wikipedia,arxiv,retriever_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ddfb23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'e:\\\\LANGGRAPH_LANGCHAIN_LANGSMITH\\\\.venv\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)), Tool(name='LangchainDocs', description='Useful for when you need to find information about Langchain', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002437C16BB50>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002432805A110>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002437C169360>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002432805A110>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]\n"
     ]
    }
   ],
   "source": [
    "print(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64850248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langsmith import Client\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "client = Client()\n",
    "prompt = client.pull_prompt(\"hwchase17/openai-functions-agent\", include_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa847a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b8b49e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2745f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3cbb6191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Hunter x Hunter'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Hunter × Hunter\n",
      "Summary: Hunter × Hunter (pronounced \"hunter hunter\") is a Japanese manga series written and illustrated by Yoshihiro Togashi. It has been serialized in Shueisha's shōnen manga magazine Weekly Shōnen Jump since March 1998, although the manga has frequently gone on extended hiatuses since 2006. Its chapters have been collected in 38 tankōbon volumes as of September 2024. The story focuses on a young boy named Gon Freecss who discovers that his father, who left him at a young age, is actually a world-renowned Hunter, a licensed professional who specializes in fantastical pursuits such as locating rare or unidentified animal species, treasure hunting, surveying unexplored enclaves, or hunting down lawless individuals. Gon departs on a journey to become a Hunter and eventually find his father. Along the way, Gon meets various other Hunters and encounters the paranormal.\n",
      "Hunter × Hunter was adapted into a 62-episode anime television series by Nippon Animation and directed by Kazuhiro Furuhashi, which ran on Fuji Television from October 1999 to March 2001. Three separate original video animations (OVAs) totaling 30 episodes were subsequently produced by Nippon Animation and released in Japan from 2002 to 2004. A second anime television series by Madhouse aired on Nippon Television from October 2011 to September 2014, totaling 148 episodes, with two animated theatrical films released in 2013. There are also numerous audio albums, video games, musicals, and other media based on Hunter × Hunter.\n",
      "The manga has been licensed for English release in North America by Viz Media since April 2005. Both television series have been also licensed by Viz Media, with the first series having aired on the Funimation Channel in 2009 and the second series broadcast on Adult Swim's Toonami programming block from April 2016 to June 2019.\n",
      "Hunter × Hunter has been widely acclaimed and commercially successful, becoming one of the best-selling manga series of all time with over 84 million copies in circulation worldwide by July 2022.\n",
      "\n",
      "Page: Hunter × Hunter (2011 TV series)\n",
      "Summary: Hunter × Hunter is an anime television series that aired from 2011 to 2014 based on Yoshihiro Togashi's manga series Hunter × Hunter. The story begins with a young boy named Gon Freecss, who one day discovers that the father who he thought was dead, is in fact alive and well. He learns that his father, Ging, is a legendary \"Hunter\", an individual who has proven themselves an elite member of humanity. Despite the fact that Ging left his son with his relatives in order to pursue his own dreams, Gon becomes determined to follow in his father's footsteps, pass the rigorous \"Hunter Examination\", and eventually find his father to become a Hunter in his own right.\n",
      "This second anime television series adaptation of Hunter × Hunter was announced on July 24, 2011. It is a complete reboot starting from the beginning of the original manga, with no connection to the first anime television series from 1999. Produced by Nippon TV, VAP, Shueisha and Madhouse, the series is directed by Hiroshi Kōjina, with Atsushi Maekawa and Tsutomu Kamishiro handling series composition, Takahiro Yoshimatsu designing the characters and Yoshihisa Hirano composing the music. Instead of having the old cast reprise their roles for the new adaptation, the series features an entirely new cast to voice the characters. The new series premiered airing weekly on Nippon TV and the nationwide Nippon News Network from October 2, 2011.  The series started to be collected in both DVD and Blu-ray format on January 25, 2012. Viz Media has licensed the anime for a DVD/Blu-ray release in North America with an English dub. On television, the series began airing on Adult Swim's Toonami programming block on April 17, 2016, and ended on June 23, 2019.\n",
      "The anime series' opening theme is alternated between the song \"Departure!\" and an alternate version titled \"Departure! -Second Version-\" both sung by Galneryus' voca\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'machine learning research papers'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2019-12-21\n",
      "Title: Machine Learning Testing: Survey, Landscapes and Horizons\n",
      "Authors: Jie M. Zhang, Mark Harman, Lei Ma, Yang Liu\n",
      "Summary: This paper provides a comprehensive survey of Machine Learning Testing (ML\n",
      "testing) research. It covers 144 papers on testing properties (e.g.,\n",
      "correctness, robustness, and fairness), testing components (e.g., the data,\n",
      "learning program, and framework), testing workflow (e.g., test generation and\n",
      "test evaluation), and application scenarios (e.g., autonomous driving, machine\n",
      "translation). The paper also analyses trends concerning datasets, research\n",
      "trends, and research focus, concluding with research challenges and promising\n",
      "research directions in ML testing.\n",
      "\n",
      "Published: 2022-02-21\n",
      "Title: Human-in-the-loop Machine Learning: A Macro-Micro Perspective\n",
      "Authors: Jiangtao Wang, Bin Guo, Liming Chen\n",
      "Summary: Though technical advance of artificial intelligence and machine learning has\n",
      "enabled many promising intelligent systems, many computing tasks are still not\n",
      "able to be fully accomplished by machine intelligence. Motivated by the\n",
      "complementary nature of human and machine intelligence, an emerging trend is to\n",
      "involve humans in the loop of machine learning and decision-making. In this\n",
      "paper, we provide a macro-micro review of human-in-the-loop machine learning.\n",
      "We first describe major machine learning challenges which can be addressed by\n",
      "human intervention in the loop. Then we examine closely the latest research and\n",
      "findings of introducing humans into each step of the lifecycle of machine\n",
      "learning. Finally, we analyze current research gaps and point out future\n",
      "research directions.\n",
      "\n",
      "Published: 2020-12-07\n",
      "Title: The Tribes of Machine Learning and the Realm of Computer Architecture\n",
      "Authors: Ayaz Akram, Jason Lowe-Power\n",
      "Summary: Machine learning techniques have influenced the field of computer\n",
      "architecture like many other fields. This paper studies how the fundamental\n",
      "machine learning techniques can be applied towards computer architecture\n",
      "problems. We also provide a detailed survey of computer architecture research\n",
      "that employs different machine learning methods. Finally, we present some\n",
      "future opportunities and the outstanding challenges that need to be overcome to\n",
      "exploit full potential of machine learning for computer architecture.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `LangchainDocs` with `{'query': 'what is Langchain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLangChain Python API Reference\n",
      "langchain-community: 0.3.29\n",
      "document_loaders\n",
      "WebBaseLoader\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WebBaseLoader#\n",
      "\n",
      "\n",
      "class langchain_community.document_loaders.web_base.WebBaseLoader(\n",
      "\n",
      "web_path: str | Sequence[str] = '',\n",
      "header_template: dict | None = None,\n",
      "verify_ssl: bool = True,\n",
      "proxies: dict | None = None,\n",
      "continue_on_failure: bool = False,\n",
      "autoset_encoding: bool = True,\n",
      "encoding: str | None = None,\n",
      "web_paths: Sequence[str] = (),\n",
      "requests_per_second: int = 2,\n",
      "default_parser: str = 'html.parser',\n",
      "requests_kwargs: Dict[str, Any] | None = None,\n",
      "raise_for_status: bool = False,\n",
      "bs_get_text_kwargs: Dict[str, Any] | None = None,\n",
      "bs_kwargs: Dict[str, Any] | None = None,\n",
      "session: Any = None,\n",
      "*,\n",
      "show_progress: bool = True,\n",
      "trust_env: bool = False,\n",
      "\n",
      ")[source]#\n",
      "WebBaseLoader document loader integration\n",
      "\n",
      "Setup:Install langchain_community.\n",
      "pip install -U langchain_community\n",
      "\n",
      "\n",
      "\n",
      "Instantiate:from langchain_community.document_loaders import WebBaseLoader\n",
      "\n",
      "document_transformers\n",
      "embeddings\n",
      "example_selectors\n",
      "graph_vectorstores\n",
      "graphs\n",
      "indexes\n",
      "llms\n",
      "memory\n",
      "output_parsers\n",
      "query_constructors\n",
      "retrievers\n",
      "storage\n",
      "tools\n",
      "utilities\n",
      "utils\n",
      "vectorstores\n",
      "\n",
      "\n",
      "Standard Tests\n",
      "\n",
      "Integrations\n",
      "\n",
      "Anthropic\n",
      "AstraDB\n",
      "AWS\n",
      "Azure Ai\n",
      "Azure Dynamic Sessions\n",
      "Cerebras\n",
      "Chroma\n",
      "Cli\n",
      "Cohere\n",
      "Db2\n",
      "Deepseek\n",
      "Elasticsearch\n",
      "Exa\n",
      "Experimental\n",
      "Fireworks\n",
      "Google Community\n",
      "Google GenAI\n",
      "Google VertexAI\n",
      "Groq\n",
      "Huggingface\n",
      "IBM\n",
      "Langchain_V1\n",
      "Milvus\n",
      "MistralAI\n",
      "MongoDB\n",
      "Neo4J\n",
      "Nomic\n",
      "Nvidia Ai Endpoints\n",
      "Ollama\n",
      "OpenAI\n",
      "Perplexity\n",
      "Pinecone\n",
      "Postgres\n",
      "Prompty\n",
      "Qdrant\n",
      "Redis\n",
      "Sema4\n",
      "Snowflake\n",
      "Sqlserver\n",
      "Tavily\n",
      "Together\n",
      "Unstructured\n",
      "Upstage\n",
      "Weaviate\n",
      "XAI\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LangChain Python API Reference\n",
      "langchain-community: 0.3.29\n",
      "document_loaders\n",
      "WebBaseLoader\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WebBaseLoader#\n",
      "\n",
      "\n",
      "class langchain_community.document_loaders.web_base.WebBaseLoader(\n",
      "\n",
      "Core\n",
      "Langchain\n",
      "Text Splitters\n",
      "Community\n",
      "adapters\n",
      "agent_toolkits\n",
      "agents\n",
      "cache\n",
      "callbacks\n",
      "chains\n",
      "chat_loaders\n",
      "chat_message_histories\n",
      "chat_models\n",
      "cross_encoders\n",
      "docstore\n",
      "document_compressors\n",
      "document_loaders\n",
      "AcreomLoader\n",
      "AirbyteCDKLoader\n",
      "AirbyteGongLoader\n",
      "AirbyteHubspotLoader\n",
      "AirbyteSalesforceLoader\n",
      "AirbyteShopifyLoader\n",
      "AirbyteStripeLoader\n",
      "AirbyteTypeformLoader\n",
      "AirbyteZendeskSupportLoader\n",
      "AirbyteJSONLoader\n",
      "AirtableLoader\n",
      "ArcGISLoader\n",
      "ArxivLoader\n",
      "AssemblyAIAudioLoaderById\n",
      "AssemblyAIAudioTranscriptLoader\n",
      "TranscriptFormat\n",
      "AsyncHtmlLoader\n",
      "AthenaLoader\n",
      "AZLyricsLoader\n",
      "AzureAIDataLoader\n",
      "AzureBlobStorageContainerLoader\n",
      "AzureBlobStorageFileLoader\n",
      "BaiduBOSDirectoryLoader\n",
      "BaiduBOSFileLoader\n",
      "O365BaseLoader\n",
      "BibtexLoader\n",
      "BiliBiliLoader\n",
      "BlackboardLoader\n",
      "CloudBlobLoader\n",
      "FileSystemBlobLoader\n",
      "YoutubeAudioLoader\n",
      "BlockchainDocumentLoader\n",
      "BlockchainType\n",
      "BraveSearchLoader\n",
      "BrowserbaseLoader\n",
      "BrowserlessLoader\n",
      "CassandraLoader\n",
      "ChatGPTLoader\n",
      "CHMParser\n",
      "UnstructuredCHMLoader\n",
      "AsyncChromiumLoader\n",
      "\n",
      "WebBaseLoader — 🦜🔗 LangChain  documentation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main content\n",
      "\n",
      "\n",
      "Back to top\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ctrl+K\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Reference\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ctrl+K\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GitHub\n",
      "\n",
      "\n",
      "\n",
      "X / Twitter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ctrl+K\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Reference\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GitHub\n",
      "\n",
      "\n",
      "\n",
      "X / Twitter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Section Navigation\n",
      "Base packages\u001b[0m\u001b[32;1m\u001b[1;3mHere are the answers to your questions:\n",
      "\n",
      "1. Hunter x Hunter is a Japanese manga series written and illustrated by Yoshihiro Togashi. It has been serialized in Shueisha's shōnen manga magazine Weekly Shōnen Jump since March 1998. The story focuses on a young boy named Gon Freecss who discovers that his father, who left him at a young age, is actually a world-renowned Hunter, a licensed professional who specializes in fantastical pursuits such as locating rare or unidentified animal species, treasure hunting, surveying unexplored enclaves, or hunting down lawless individuals.\n",
      "\n",
      "2. Here are a few research papers on machine learning:\n",
      "* \"Machine Learning Testing: Survey, Landscapes and Horizons\" by Jie M. Zhang, Mark Harman, Lei Ma, and Yang Liu (2019)\n",
      "* \"Human-in-the-loop Machine Learning: A Macro-Micro Perspective\" by Jiangtao Wang, Bin Guo, and Liming Chen (2022)\n",
      "* \"The Tribes of Machine Learning and the Realm of Computer Architecture\" by Ayaz Akram and Jason Lowe-Power (2020)\n",
      "\n",
      "You can find these papers on arXiv or other academic databases.\n",
      "\n",
      "3. Langchain is a Python library that provides a simple and efficient way to work with large language models. It allows users to easily integrate language models into their applications, and provides a range of tools and features for tasks such as text generation, language translation, and question answering. Langchain is designed to be flexible and customizable, and can be used with a variety of language models and frameworks.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is hunter x hunter about? also find me a research paper on machine learning and give me the link to the paper and also tell me what is Langchain?',\n",
       " 'output': 'Here are the answers to your questions:\\n\\n1. Hunter x Hunter is a Japanese manga series written and illustrated by Yoshihiro Togashi. It has been serialized in Shueisha\\'s shōnen manga magazine Weekly Shōnen Jump since March 1998. The story focuses on a young boy named Gon Freecss who discovers that his father, who left him at a young age, is actually a world-renowned Hunter, a licensed professional who specializes in fantastical pursuits such as locating rare or unidentified animal species, treasure hunting, surveying unexplored enclaves, or hunting down lawless individuals.\\n\\n2. Here are a few research papers on machine learning:\\n* \"Machine Learning Testing: Survey, Landscapes and Horizons\" by Jie M. Zhang, Mark Harman, Lei Ma, and Yang Liu (2019)\\n* \"Human-in-the-loop Machine Learning: A Macro-Micro Perspective\" by Jiangtao Wang, Bin Guo, and Liming Chen (2022)\\n* \"The Tribes of Machine Learning and the Realm of Computer Architecture\" by Ayaz Akram and Jason Lowe-Power (2020)\\n\\nYou can find these papers on arXiv or other academic databases.\\n\\n3. Langchain is a Python library that provides a simple and efficient way to work with large language models. It allows users to easily integrate language models into their applications, and provides a range of tools and features for tasks such as text generation, language translation, and question answering. Langchain is designed to be flexible and customizable, and can be used with a variety of language models and frameworks.'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"what is hunter x hunter about? also find me a research paper on machine learning and give me the link to the paper and also tell me what is Langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c28fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LANGGRAPH_LANGCHAIN_LANGSMITH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
